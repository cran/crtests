<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Sjoerd van der Spoel" />

<meta name="date" content="2016-05-20" />

<title>Classification and Regression Tests</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Classification and Regression Tests</h1>
<h4 class="author"><em>Sjoerd van der Spoel</em></h4>
<h4 class="date"><em>2016-05-20</em></h4>



<p>This package provides functions for preparing data, training models, testing models, and evaluating the outcomes. Its goal is to be an extendable application programming interface (API) to creating and testing predictions made through machine learning.</p>
<p>The package aims create and run tests for two different machine learning problems: classification and regression. Classification predicts a categorical outcome, whereas regression predicts a continuous outcome. Both problems require different approaches to data preparation, modeling and evaluation.</p>
<div id="package-functions" class="section level2">
<h2>Package functions</h2>
<p>The main package functions fall into one of six categories:</p>
<ul>
<li>A function for creating a test. This sets up the test data, splitting it into training and holdout sets.</li>
<li>Functions for running a test. These call all the functions necessary to execute a test.</li>
<li>Functions for preparing data for a test. This includes problem-specific &amp; method-specific data preparation</li>
<li>Functions for training a model. These are wrapper functions to underlying machine learning functions from other packages</li>
<li>Functions for testing a model. These are wrapper functions to [code] predict, using each machine learning function’s own implementation.</li>
<li>Functions for evaluating test results. These functions compare observations with the predictions produced by testing the model.</li>
<li>Functions for running multiple instances of a test. These functions run a test multiple times on different samples of the data</li>
</ul>
<div id="creating-and-running-a-test" class="section level3">
<h3>Creating and running a test</h3>
<p>The required parameters to creating a test using <code>createtest</code> are a dataset, a dependent variable, a problem and a method, a name, and finally an index of the rows to use as training set.</p>
<p><code>createtest</code> checks that its inputs are not missing and are in the right shape. If possible, it will try to fix issues. For example, classification requires the dependent variable to be a factor, but <code>createtest</code> will convert other vector types. Furthermore, <code>createtest</code> tries to provide informative messages when it cannot fix an issue.</p>
<p>It returns a list of the class determined by the <em>problem</em> parameter. This class determines, amongst others, which preparation, training, testing and evaluation functions will be called by <code>runtest</code>.</p>
<p>The structure of the return value (the test) is as follows:</p>
<dl>
<dt>dependent</dt>
<dd>The fully specified column name of the dependent variable.
</dd>
<dt>problem</dt>
<dd>The type of problem for the test (classification or regression). This is therefore the same as the test class
</dd>
<dt>data</dt>
<dd>The list of train and holdout data.frames.
</dd>
<dt>name</dt>
<dd>The name of the test. This could be used when printing the test results
</dd>
<dt>description</dt>
<dd>A description of the test.
</dd>
<dt>method</dt>
<dd>The method that should be used for solving the problem: a single-item list of class method. This is used to determine which functions are to be called for creating a model and making predictions with that model
</dd>
<dt>extra.args</dt>
<dd>Extra arguments that should be passed to the runtest method executing the test. These are not used in the package, but exist for extendability.
</dd>
<dt>call</dt>
<dd>The call to the <code>createtest</code> function. Again, this could be used when printing the test results, so it is obvious at a glance what the test was about.
</dd>
</dl>
</div>
<div id="functions-for-running-a-test" class="section level3">
<h3>Functions for running a test</h3>
<p>The package provides the <code>runtest</code> generic function, which allows execution to be redirected based on the class of the test. Although there are perhaps cases where this distinction is meaningful, the package only provides <code>runtest.default</code>.</p>
<p>The default implementation first calls <code>prepare</code>. It calls <code>train_model</code> with the data from <code>prepare</code>. It calls <code>make_predictions</code> with the model from <code>train_model</code>. It calls <code>evaluate</code> with the predictions from <code>make_predictions</code> and the holdout set from <code>prepare</code> and returns the result.</p>
</div>
<div id="functions-for-preparing-data" class="section level3">
<h3>Functions for preparing data</h3>
<p>The main preparation function is <code>prepare</code>. It is a generic function, which allows for different implementations for the different class of problems. However, the package itself only provides <code>prepare.default</code>, as it provides generic data preparation that is suitable to both regression and classification.</p>
<p><code>prepare.default</code> calls a helper function <code>prepare_data</code>, which removes all missing values and provides informative messages of what happened. Furthermore, this function deals with an issue some algorithms can’t deal with: different levels for factors in the train and holdout sets. To deal with this, it calls <code>apply_levels</code>. <code>apply_levels</code> goes through the data column by column, and replaces the levels of the factors in the holdout sets by those of the same column in the training set.</p>
<p>Finally, <code>prepare.default</code> calls <code>method_prepare</code>. This generic functions makes it possible to have machine learning method-specific data preparation. These functions are called with the <em>method</em> attribute of the test object. Most methods do not need specific preparation, so <code>method_prepare.default</code> simply returns <code>identity(data)</code>. Random Forests do need method specific preparation, as they cannot deal with categorical predictors with more than 32 categories. Therefore <code>method_prepare.randomForest</code> uses <code>group_levels</code> to group infrequent factor levels to make sure no factor has more than 32 levels.</p>
</div>
<div id="functions-for-training-a-model" class="section level3">
<h3>Functions for training a model</h3>
<p>The <code>train_model</code> functions trains or fits a model to the data through some form of machine learning or statistical technique. There exist two implementations: <code>train_model.classification</code> for creating a classification model and <code>train_model.regression</code> for fitting a regression model.</p>
<p><code>train_model.classification</code> wraps <code>classification_model</code>, of which <code>classification_model.default</code> calls a machine learning method with parameters <code>x</code>, <code>y</code> and <code>data</code>. <code>classification_model</code> exists so method-specific implementations can be made that need other parameters. For example, <code>rpart</code> requires a <code>formula</code>, so <code>classification_model.rpart</code> makes one from the <em>dependent</em> variable of the test object.</p>
<p><code>train_model.regression</code> is the analogue of <code>train_model.classification</code> for regression. It calls <code>regression_model</code> with parameters <code>formula</code> and <code>data</code>. Again, methods can have their own implementations.</p>
</div>
<div id="functions-for-testing-a-model" class="section level3">
<h3>Functions for testing a model</h3>
<p>The <code>make_predictions</code> functions serve as a wrapper to <code>predict</code>. <code>make_predictions.default</code> calls <code>predict</code> with the holdout set as <code>newdata</code> and the <em>model</em> produced by <code>train_model</code>. If a machine learning methods requires different parameters, the solution is an implementation of <code>make_predictions</code> for that method. For example <code>predict.rpart</code> needs a <code>type</code> attribute, so <code>make_predictions.rpart</code> was developed.</p>
</div>
<div id="functions-for-evaluating-test-results" class="section level3">
<h3>Functions for evaluating test results</h3>
<p>The <code>evaluate</code> functions evaluate the performance of a model. <code>evaluate.default</code> extracts the dependent variable from the holdout set (the <code>observations</code>) and the <code>predictions</code> from <code>make_predictions</code> and calls its helper method <code>evaluate_problem</code>.</p>
<p><code>evaluate_problem.classification</code> calls <code>caret::confusionMatrix</code>. <code>evaluate_problem.regression</code> returns a <code>summary</code> of <code>observations - predictions</code>.</p>
</div>
<div id="functions-for-running-multiple-instances-of-a-test" class="section level3">
<h3>Functions for running multiple instances of a test</h3>
<p>As a convenience, the package provides a function to run multiple instances of a test: <code>multitest</code>. The parameters to this method are mostly just passed along to <code>createtest</code> via <code>create_and_run_test</code>. The other parameters govern the sampling method used, as the goal of multiple runs of a test usually is to reduce sample bias.</p>
<p>There are two options: cross-fold, which makes sure every row of data is used a holdout once; and random, which randomly selects a percentage of the data for training. These are implemented by <code>multisample.cross_fold</code> and <code>multisample.random</code> respectively.</p>
</div>
</div>
<div id="example-creating-and-running-a-test" class="section level2">
<h2>Example: creating and running a test</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(crtests)
<span class="kw">library</span>(randomForest)</code></pre></div>
<pre><code>## randomForest 4.6-12</code></pre>
<pre><code>## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)</code></pre></div>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## 
## Attaching package: 'ggplot2'</code></pre>
<pre><code>## The following object is masked from 'package:randomForest':
## 
##     margin</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(iris)
<span class="co"># A classification test</span>
test &lt;-<span class="st"> </span><span class="kw">createtest</span>(<span class="dt">data =</span> iris, 
                   <span class="dt">dependent =</span> <span class="st">&quot;Species&quot;</span>,
                   <span class="dt">problem =</span> <span class="st">&quot;classification&quot;</span>,
                   <span class="dt">method =</span> <span class="st">&quot;randomForest&quot;</span>,
                   <span class="dt">name =</span> <span class="st">&quot;An example classification test&quot;</span>,
                   <span class="dt">train_index =</span> <span class="kw">sample</span>(<span class="dv">150</span>, <span class="dv">100</span>)
                   )
<span class="kw">runtest</span>(test)</code></pre></div>
<pre><code>## Classification Test Evaluation: An example classification test
## 
## Test attributes:
##                                                
##                    Method : randomForest       
##        Dependent variable : Species            
##       Percentage held out : 33.33333% (50 rows)
##        Total rows in data : 150                
##       Data transformation : None               
## 
## Performance measures &amp; statistics:
##                                                 
##                  Accuracy : 0.92                
##                    95% CI : 0.8076572, 0.9777720
##       No information rate : 0.42                
##  P-value (accuracy &gt; NIR) : 1.296044e-13        
##    McNemar's test P-value : NaN</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># A regression test</span>
test &lt;-<span class="st"> </span><span class="kw">createtest</span>(<span class="dt">data =</span> iris,
                   <span class="dt">dependent =</span> <span class="st">&quot;Sepal.Width&quot;</span>,
                   <span class="dt">problem =</span> <span class="st">&quot;regression&quot;</span>,
                   <span class="dt">method =</span> <span class="st">&quot;randomForest&quot;</span>,
                   <span class="dt">name =</span> <span class="st">&quot;An example regression test&quot;</span>,
                   <span class="dt">train_index =</span> <span class="kw">sample</span>(<span class="dv">150</span>,<span class="dv">100</span>)
                   )
<span class="kw">runtest</span>(test)</code></pre></div>
<pre><code>## Regression Test Evaluation: An example regression test
## 
## Test attributes:
##                                                      
##                          Method : randomForest       
##              Dependent variable : Sepal.Width        
##             Percentage held out : 33.33333% (50 rows)
##              Total rows in data : 150                
##             Data transformation : None               
## 
## Performance measures &amp; statistics:
##                                             
##                      Mean error : 0.05295918
##             Mean absolute error : 0.2716197 
##               Mean square error : 0.1139226 
##  Mean absolute percentage error : 9.173828  
##          Root mean square error : 0.3375242</code></pre>
</div>
<div id="example-running-multiple-instances-of-a-test" class="section level2">
<h2>Example: running multiple instances of a test</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(crtests)
<span class="kw">library</span>(randomForest)
<span class="kw">library</span>(rpart)
<span class="kw">library</span>(caret)
<span class="kw">library</span>(stringr)

<span class="co"># A classification multitest</span>
<span class="kw">summary</span>(
  <span class="kw">multitest</span>(<span class="dt">data =</span> iris,
            <span class="dt">dependent =</span> <span class="st">&quot;Species&quot;</span>,
            <span class="dt">problem =</span> <span class="st">&quot;classification&quot;</span>,
            <span class="dt">method =</span> <span class="st">&quot;randomForest&quot;</span>,
            <span class="dt">name =</span> <span class="st">&quot;An example classification multitest&quot;</span>,
            <span class="dt">iterations =</span> <span class="dv">10</span>,
            <span class="dt">cross_validation =</span> <span class="ot">TRUE</span>,
            <span class="dt">preserve_distribution =</span> <span class="ot">TRUE</span>
           )
)</code></pre></div>
<pre><code>## Classification Multiple Test Evaluation: An example classification multitest 
## 
## Test attributes:
## 
## General:
##                                                         
##                    Method: randomForest                 
##        Dependent variable: Species                      
##       Data transformation: identity                     
##           Sampling method: 10-fold cross validation with
##                            preservation of class        
##                            distribution                 
## 
## Summary of attributes per test iteration:
## 
##                            Min. 1st Qu. Median Mean 3rd Qu. Max.
##              Rows held out   30      30     30   30      30   30
##         Total rows in data  150     150    150  150     150  150
## 
## Performance measures:
## 
##                                Min.  1st Qu.   Median     Mean  3rd Qu.
##                   Accuracy 9.00e-01 9.33e-01 9.67e-01 9.57e-01 9.92e-01
##      Lower bound of 95% CI 7.35e-01 7.79e-01 8.28e-01 8.16e-01 8.70e-01
##      Upper bound of 95% CI 9.79e-01 9.92e-01 9.99e-01 9.94e-01 1.00e+00
##        No information rate 3.33e-01 3.33e-01 3.33e-01 3.33e-01 3.33e-01
##   P-value (accuracy &gt; NIR) 4.86e-15 7.77e-14 2.96e-13 3.51e-11 8.75e-12
##     McNemar's test P-value       NA       NA       NA      NaN       NA
##                                Max.
##                   Accuracy 1.00e+00
##      Lower bound of 95% CI 8.84e-01
##      Upper bound of 95% CI 1.00e+00
##        No information rate 3.33e-01
##   P-value (accuracy &gt; NIR) 1.66e-10
##     McNemar's test P-value       NA</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># A regression multitest</span>
<span class="kw">summary</span>(
  <span class="kw">multitest</span>(<span class="dt">data =</span> iris,
            <span class="dt">dependent =</span> <span class="st">&quot;Sepal.Width&quot;</span>,
            <span class="dt">problem =</span> <span class="st">&quot;regression&quot;</span>,
            <span class="dt">method =</span> <span class="st">&quot;rpart&quot;</span>,
            <span class="dt">name =</span> <span class="st">&quot;An example regression multitest&quot;</span>,
            <span class="dt">iterations =</span> <span class="dv">15</span>,
            <span class="dt">cross_validation =</span> <span class="ot">FALSE</span>
           )
)</code></pre></div>
<pre><code>## Regression Multiple Test Evaluation: An example regression multitest 
## 
## Test attributes:
## 
## General:
##                                                   
##                          Method: rpart            
##              Dependent variable: Sepal.Width      
##             Data transformation: identity         
##                 Sampling method: 15 random samples
## 
## Summary of attributes per test iteration:
## 
##                                  Min. 1st Qu. Median Mean 3rd Qu. Max.
##                    Rows held out   10      10     10   10      10   10
##               Total rows in data  150     150    150  150     150  150
## 
## Performance measures:
## 
##                                     Min. 1st Qu.  Median     Mean 3rd Qu.
##                       Mean error -0.1656 -0.0771 -0.0246 -0.00589  0.0765
##              Mean absolute error  0.1281  0.2143  0.2398  0.25130  0.3067
##                Mean square error  0.0284  0.0639  0.0882  0.10140  0.1173
##   Mean absolute percentage error  4.3920  7.2340  8.5740  8.42900 10.4700
##           Root mean square error  0.1685  0.2526  0.2971  0.30900  0.3426
##                                    Max.
##                       Mean error  0.222
##              Mean absolute error  0.370
##                Mean square error  0.224
##   Mean absolute percentage error 12.810
##           Root mean square error  0.473</code></pre>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
